{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tables\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hdf5_path = '/Users/chetan/Documents/Git Projects/Machine Learning Projects/Computer Vision Problem/Dataset/dataset.hdf5'  # path of the dataset.hdf5 file\n",
    "subtract_mean = True\n",
    "batch_size = 50\n",
    "nb_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_file = tables.open_file(hdf5_path, mode='r')\n",
    "# subtract the training mean\n",
    "if subtract_mean:\n",
    "    mm = hdf5_file.root.train_mean[0]\n",
    "    mm = mm[np.newaxis, ...]\n",
    "\n",
    "# Total number of samples\n",
    "train_data = np.array(hdf5_file.root.train_img)\n",
    "train_label = np.array(hdf5_file.root.train_labels)\n",
    "\n",
    "test_data = np.array(hdf5_file.root.test_img)\n",
    "test_label = np.array(hdf5_file.root.test_labels)\n",
    "\n",
    "val_data = np.array(hdf5_file.root.val_img)\n",
    "val_label = np.array(hdf5_file.root.val_labels)\n",
    "\n",
    "print('train data:',train_data.shape,' train_label',train_label.shape)\n",
    "print('test_data:',test_data.shape,' test_label:',test_label.shape)\n",
    "print('val_data:',val_data.shape,' val_label:',val_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "# one-hot encode the labels\n",
    "num_classes = len(np.unique(train_label))\n",
    "train_label = np_utils.to_categorical(train_label, num_classes)\n",
    "test_label = np_utils.to_categorical(test_label, num_classes)\n",
    "val_label = np_utils.to_categorical(val_label, num_classes)\n",
    "\n",
    "# print shape of training set\n",
    "print('num_classes:', num_classes)\n",
    "\n",
    "# print number of training, validation, and test images\n",
    "print(train_label.shape, 'train samples')\n",
    "print(test_label.shape, 'test samples')\n",
    "print(val_label.shape, 'validation samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=2, padding='same', activation='relu', \n",
    "                        input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=32, kernel_size=2, padding='same', activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='tanh'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "hist = model.fit(train_data, train_label, batch_size=None, epochs=20,\n",
    "          validation_data=(val_data, val_label),callbacks=[checkpointer], \n",
    "          verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('model.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(test_data, test_label, verbose=0)\n",
    "print('\\n', 'Test accuracy:', score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
